{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by loading up our bulldozers data.  We'll begin with our data pre-processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalesID</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>MachineID</th>\n",
       "      <th>ModelID</th>\n",
       "      <th>datasource</th>\n",
       "      <th>auctioneerID</th>\n",
       "      <th>YearMade</th>\n",
       "      <th>MachineHoursCurrentMeter</th>\n",
       "      <th>UsageBand</th>\n",
       "      <th>fiModelDesc</th>\n",
       "      <th>...</th>\n",
       "      <th>saleDay</th>\n",
       "      <th>saleDayofweek</th>\n",
       "      <th>saleDayofyear</th>\n",
       "      <th>saleIs_month_end</th>\n",
       "      <th>saleIs_month_start</th>\n",
       "      <th>saleIs_quarter_end</th>\n",
       "      <th>saleIs_quarter_start</th>\n",
       "      <th>saleIs_year_end</th>\n",
       "      <th>saleIs_year_start</th>\n",
       "      <th>saleElapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7648</th>\n",
       "      <td>1165000</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>733687</td>\n",
       "      <td>7057</td>\n",
       "      <td>121</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>4368.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>312</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1073260800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8228</th>\n",
       "      <td>1166933</td>\n",
       "      <td>10750.0</td>\n",
       "      <td>1035166</td>\n",
       "      <td>8861</td>\n",
       "      <td>121</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2002</td>\n",
       "      <td>603.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>803</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1073606400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SalesID  SalePrice  MachineID  ModelID  datasource  auctioneerID  \\\n",
       "7648  1165000    27000.0     733687     7057         121           3.0   \n",
       "8228  1166933    10750.0    1035166     8861         121           3.0   \n",
       "\n",
       "      YearMade  MachineHoursCurrentMeter UsageBand fiModelDesc  ... saleDay  \\\n",
       "7648      1995                    4368.0    Medium         312  ...       5   \n",
       "8228      2002                     603.0       Low         803  ...       9   \n",
       "\n",
       "     saleDayofweek saleDayofyear saleIs_month_end saleIs_month_start  \\\n",
       "7648             0             5            False              False   \n",
       "8228             4             9            False              False   \n",
       "\n",
       "     saleIs_quarter_end saleIs_quarter_start saleIs_year_end  \\\n",
       "7648              False                False           False   \n",
       "8228              False                False           False   \n",
       "\n",
       "     saleIs_year_start saleElapsed  \n",
       "7648             False  1073260800  \n",
       "8228             False  1073606400  \n",
       "\n",
       "[2 rows x 65 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_sorted = pd.read_csv('./bulldozers_sorted.csv', index_col = 0)\n",
    "df_sorted[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our salesdata column is already coerced into multiple different numerical columns.  And the only features that are not numeric are our categorical features, which is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sorted.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's separate our data into the features, $X$, and the target $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_sorted.drop('SalePrice', axis = 1)\n",
    "y = df_sorted['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's split our data into training, validation and test sets.  We set `shuffle = False` as we want our datasets ordered by time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, shuffle = False)\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_test, y_test, test_size = .5, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's again find the categorical columns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,\n",
       "       24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n",
       "       41, 42, 43, 44, 45, 46, 47, 48, 49, 50])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "cal_col_idcs = np.where(X.dtypes == np.object)[0]\n",
    "cal_col_idcs\n",
    "\n",
    "# array([ 7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,\n",
    "#        24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n",
    "#        41, 42, 43, 44, 45, 46, 47, 48, 49, 50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's create our datapools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "train_pool = Pool(X_train, y_train, cat_features = cal_col_idcs)\n",
    "validate_pool = Pool(X_validate, y_validate, cat_features = cal_col_idcs)\n",
    "test_pool = Pool(X_test, y_test, cat_features = cal_col_idcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8094531821829951"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'iterations': 200, 'depth':6,  \n",
    "          'logging_level':'Silent', \n",
    "          'random_seed':42}\n",
    "\n",
    "cbr = CatBoostRegressor(**params).fit(train_pool)\n",
    "\n",
    "\n",
    "cbr.score(validate_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if we can improve our score by tuning hyperparameters.  \n",
    "\n",
    "Let's begin with the `min_child_samples` hyperparameter.  Let's set min samples between 4 and 12, going by 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples = list(range(3, 13, 2))\n",
    "np.arrange(4, 12, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Min Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_min_samples = [CatBoostRegressor(iterations=200,\n",
    "                                  max_depth=13, \n",
    "                                  min_child_samples = min_sample,\n",
    "                                  logging_level = 'Silent').fit(train_pool) \n",
    "                for min_sample in min_samples]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a series with the labels as the the min_child_samples values and the values as the corresponding validation scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like `min_child_samples` of ?? is the value that optimizes our score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Max depth "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's move onto max depth.  The maximum value that catboost allows for max_depth is 16.  So let's try values between 4 and 16.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = range(5, 16, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_depths = [CatBoostRegressor(iterations=200,\n",
    "                                  max_depth=max_depth, \n",
    "                                  logging_level = 'Silent').fit(train_pool) \n",
    "                for max_depth in max_depths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a series with the labels as the the `max_depth` values and the values as the corresponding validation scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Column Sample by Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "col_sample_pcts = np.linspace(0.1, 1, 10)\n",
    "col_sample_pcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sample_pcts = [CatBoostRegressor(iterations=200,\n",
    "                                  max_depth=13, \n",
    "                                  colsample_bylevel = pct,\n",
    "                                  logging_level = 'Silent').fit(train_pool) \n",
    "                for pct in col_sample_pcts]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_learn = CatBoostRegressor(iterations=3000, max_depth=13, learning_rate = .01,\n",
    "                                colsample_bylevel = .1,\n",
    "                                logging_level = 'Silent').fit(train_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_learn.score(validate_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Try more iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_learn = CatBoostRegressor(iterations=4000, max_depth=13, learning_rate = .01,\n",
    "                                colsample_bylevel = .1,\n",
    "                                logging_level = 'Silent').fit(train_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_learn.score(validate_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Cut learning rate in half and double score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_learn = CatBoostRegressor(iterations=6000, max_depth=13, learning_rate = .005,\n",
    "                                colsample_bylevel = .1,\n",
    "                                logging_level = 'Silent').fit(train_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_learn.score(validate_pool)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
