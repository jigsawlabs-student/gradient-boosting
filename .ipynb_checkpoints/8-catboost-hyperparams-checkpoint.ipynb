{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll work through different hyperparameters that are available to tune in catboost.  As we'll see, catboost is quite sensitive hyperparameter tuning.  By the end of this lesson, we'll see an improvement in our score from .35 to .52 -- roughly 1.5 times our original score.  Also, we'll see that many of the hyperparameters that we can tune are similar to those available in a random forest.  Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load up our data, and get it to train a catboost regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "df = pd.read_csv('./imdb_movies.csv')\n",
    "df_sorted = df.sort_values(['year', 'month'])\n",
    "X = df_sorted.iloc[:, 1:-1]\n",
    "y = df_sorted['revenue']\n",
    "\n",
    "genre = X['genre']\n",
    "genre_filled = genre.fillna(-999).astype('category')\n",
    "X_updated = X.assign(genre = genre_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So after replacing our na values, and changing the type to category, we can split our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_updated, y, shuffle = False, test_size = .2)\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_test, y_test, shuffle = False, test_size = .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we identify our categorical columns and create our Pools for the training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "cat_indices = np.where(X.dtypes == np.object)[0]\n",
    "cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(X_train, \n",
    "                  y_train, \n",
    "                  cat_features=[0])\n",
    "\n",
    "validate_pool = Pool(X_validate, \n",
    "                  y_validate, \n",
    "                  cat_features=[0])\n",
    "\n",
    "test_pool = Pool(X_test, \n",
    "                  y_test, \n",
    "                  cat_features=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's train an initial model to check if need any further modifications to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x125000590>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbr = CatBoostRegressor(logging_level = 'Silent')\n",
    "cbr.fit(train_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are a number of hyperparameters we can set with catboost.  Many of them are equivalent to what we saw with random forests.  \n",
    "\n",
    "* `iterations`: `n_estimators`\n",
    "* `min_child_samples`: `min_samples_leaf`\n",
    "* `colsample_bylevel`: `max_features`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through these parameters to get familiar with the process of tuning our hyperparameters.  We can view even more hyperparameters by visiting the [parameters in the documentation](https://catboost.ai/docs/concepts/python-reference_parameters-list.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify an initial list of hyperparameters as a dictionary.  Notice that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'iterations': 500,\n",
    "    'learning_rate': 0.1,\n",
    "    'min_child_samples': 7,\n",
    "    'eval_metric': 'RMSE',\n",
    "    'random_seed': 42,\n",
    "    'logging_level': 'Silent'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can use the splat operator to pass them through as arguments to our regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x12624fbd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbr_2 = CatBoostRegressor(**params)\n",
    "cbr_2.fit(train_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35573315143164774"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbr_2.score(validate_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's begin the process of trying our different hyperparameters.  Because training a catboost model can be time consuming there are couple of techniques that we can help speed up training time.  \n",
    "\n",
    "The first is setting the `task_type = 'GPU'`.  Now, this will only work if an Nvidia driver is present on the computer (which for a Macbook Pro it is not).  But in Google Colab, we can go to `Runtime > Change Runtime Type`.  \n",
    "\n",
    "Ok, now let's begin with hyperparameter tuning,  starting with `max_depth`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tuning max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform hyperparameter tuning the same we did previously.  We loop through different values of our hyperparameter and evaluate the score.  Catboost doesn't allow max depth to exceed 16, so we'll try values between 5 and 15 going by 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 7, 9, 11, 13, 15]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depths = list(range(5, 16, 2))\n",
    "max_depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Then we train the model at each of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_depths = [CatBoostRegressor(iterations=200,\n",
    "                                  max_depth=max_depth, \n",
    "                                  logging_level = 'Silent').fit(train_pool) \n",
    "                for max_depth in max_depths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     0.312708\n",
       "7     0.353376\n",
       "9     0.421708\n",
       "11    0.454850\n",
       "13    0.470696\n",
       "15    0.441350\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(index = max_depths, data = [model.score(validate_pool) for model in model_depths])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the top score is 13, so let's also try 12, and 14.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_depths = [CatBoostRegressor(iterations=200,\n",
    "                                  max_depth=max_depth, \n",
    "                                  logging_level = 'Silent').fit(train_pool) \n",
    "                for max_depth in [12, 14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.48008950374793147, 0.44431330627021737]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.score(validate_pool) for model in model_depths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that max_depth at 12 is slightly higher, so we'll go with that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Tuning min_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because catboost tries to maintain an even split, there is not as strong a benefit to working with `min_child_samples` as in random forests, which can have uneven splits.  So let's just try a few values to see if there is any benefit.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 7, 11]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_samples = list(range(3, 13, 4))\n",
    "min_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_min_samples = [CatBoostRegressor(iterations=200,\n",
    "                                  max_depth=12, \n",
    "                                  min_child_samples = min_sample,\n",
    "                                  logging_level = 'Silent').fit(train_pool) \n",
    "                for min_sample in min_samples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     0.48009\n",
       "7     0.48009\n",
       "11    0.48009\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(index = min_samples, data = [model.score(validate_pool) for model in model_min_samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So we can see that the `min_child_samples` does not have an impact on this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  `col_sample_by_level`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can try to tune the `col_sample_by_level` hyperparameter.  Remember that this hyperparameter randomly selects a subsample of features before each split.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "col_sample_pcts = np.linspace(0.1, 1, 10)\n",
    "col_sample_pcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_sample_pcts = [CatBoostRegressor(iterations=200,\n",
    "                                  max_depth=12, \n",
    "                                  colsample_bylevel = pct,\n",
    "                                  logging_level = 'Silent').fit(train_pool) \n",
    "                for pct in col_sample_pcts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1    0.501423\n",
       "0.2    0.470952\n",
       "0.3    0.426782\n",
       "0.4    0.457420\n",
       "0.5    0.496440\n",
       "0.6    0.483795\n",
       "0.7    0.471304\n",
       "0.8    0.486244\n",
       "0.9    0.429902\n",
       "1.0    0.470696\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(index = col_sample_pcts, data = [model.score(validate_pool) for model in model_sample_pcts])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here it could be either .5 or .1 as our ideal choice.  Let's try multiple models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sample at $.1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> First, we'll try multiple attempts at setting a `colsample_bylevel` at .1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_models_one_tenth = [CatBoostRegressor(iterations=1000, max_depth=12,  \n",
    "                                colsample_bylevel = .1, random_state = i,\n",
    "                                logging_level = 'Silent').fit(train_pool) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5064435852154457,\n",
       " 0.49885520382008475,\n",
       " 0.4794802112328914,\n",
       " 0.5152191341463006,\n",
       " 0.45917077043233556]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_tenth_scores = [model.score(validate_pool) for model in random_models_one_tenth]\n",
    "one_tenth_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49183378096941155, 0.02252279092798799)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_tenth = pd.Series(one_tenth_scores)\n",
    "one_tenth.mean(), one_tenth.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Then let's try to tune multiple models at `.5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_models_one_half = [CatBoostRegressor(iterations=1000, max_depth=12,  \n",
    "                                colsample_bylevel = .5, random_state = i,\n",
    "                                logging_level = 'Silent').fit(train_pool) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4715609966945278,\n",
       " 0.4456166963451539,\n",
       " 0.4766053657585869,\n",
       " 0.48250848881947983]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_half_scores = [model.score(validate_pool) for model in random_models]\n",
    "one_half_scores[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46965481592254266, 0.014145759347158896)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_half = pd.Series(one_half_scores)\n",
    "one_half.mean(), one_half.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it appears that using `colsample_bylevel = .1` provides the strongest increase in the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning l2 regularization leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now l2 regularization is hyperparameter that we have not seen before with tree based models.  The basic idea is that there is increased variance as our trees become more complex -- as they have more splits.  So with l2 regularization, there the decision tree will only continue to split if there is a significant improvement from not splitting.  The threshold of improvement needed is determined by the hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9, 11]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_vals = list(range(1, 12, 2))\n",
    "l2_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_models = [CatBoostRegressor(iterations=1000, max_depth=12,  \n",
    "                                colsample_bylevel = .1,\n",
    "                                logging_level = 'Silent', l2_leaf_reg = val).fit(train_pool) for val in l2_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5210297767132677,\n",
       " 0.5195998473448362,\n",
       " 0.5285313071922895,\n",
       " 0.5272492438928775,\n",
       " 0.5297997737844614,\n",
       " 0.5264380609616861]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.score(validate_pool) for model in l2_models]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we begin to see a bump as we get upwards of 9 and 11.  Let's try higher numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_models = [CatBoostRegressor(iterations=1000, max_depth=12,  \n",
    "                                colsample_bylevel = .1,\n",
    "                                logging_level = 'Silent', l2_leaf_reg = val).fit(train_pool) for val in [13, 15, 17]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5246821966369193, 0.5202944091370997, 0.5210612140544018]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.score(validate_pool) for model in l2_models]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we see a peak right around 9.  Let's now just try values 8 and 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_models_eight_ten = [CatBoostRegressor(iterations=1000, max_depth=12,  \n",
    "                                colsample_bylevel = .1,\n",
    "                                logging_level = 'Silent', l2_leaf_reg = val).fit(train_pool) for val in [8, 10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5273739387034617, 0.5238129670744792]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.score(validate_pool) for model in l2_models_eight_ten]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that the top value is when we had `l2_leaf_reg = 9`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now it's time to work with setting the learning rate.  The general rule is that the lower the learning rate, the more the number of iterations we'll need to converge.  To prevent our model from overfitting, we can use the overfitting detector, which will stop our model when there is no longer an improvement on the validation set to adding more trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To use the overfitting detector we need to pass through the validation pool when we fit the model.  And we have to specify our overfitting detector -- here `od_type = 'Iter'`, and the `od_wait = 40` means we stop training if there is no improvement for 40 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_learn = CatBoostRegressor(iterations=5000, learning_rate = .01,\n",
    "                                max_depth=12, l2_leaf_reg = 9,\n",
    "                                colsample_bylevel = .1, od_type='Iter', od_wait = 40,\n",
    "                                logging_level = 'Silent').fit(train_pool, eval_set = validate_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at the best score and best iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learn': {'RMSE': 135963397.37969565},\n",
       " 'validation': {'RMSE': 186490337.30068162}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_learn.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2851"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_learn.best_iteration_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5274538836079761"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_learn.score(validate_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now that we found the best score for a learning rate of .01, let's cut the learning the rate in half and double the number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_smaller_learn = CatBoostRegressor(iterations=6000, learning_rate = .005,\n",
    "                                max_depth=12, l2_leaf_reg = 9,\n",
    "                                colsample_bylevel = .1, od_type='Iter', od_wait = 40,\n",
    "                                logging_level = 'Silent').fit(train_pool, eval_set = validate_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learn': {'RMSE': 141581067.4139003},\n",
       " 'validation': {'RMSE': 188935636.04809418}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_smaller_learn.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3407"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_smaller_learn.best_iteration_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3408"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_smaller_learn.tree_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5149804002794596"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_smaller_learn.score(validate_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see a slightly smaller score, which is likely due to random variation in our trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we learned about hyperparameter tuning for the catboost regressor.  We saw that some of the parameters are pretty similar to what we saw with a random forest regressor.\n",
    "\n",
    "* `iterations`: `n_estimators`\n",
    "* `min_child_samples`: `min_samples_leaf`\n",
    "* `colsample_bylevel`: `max_features`\n",
    "\n",
    "And we tune our hyperparameters in the same way: we loop through different values and assess the score on the validation set.  \n",
    "\n",
    "Then we explored some hyperparameters that were a bit different.  The first is `l2_leaf_reg`, by which will only a tree will only split if there is sufficient gain ahead of some threshold.  This is another mechanism of balancing the bias-variance tradeoff, as increasing a split increases the variance.  And preventing a split limits a tree to find a potential pattern in the data.\n",
    "\n",
    "The second was the hyperparameter we worked with was the number of trees/learning rate.  We were able to determine the number of trees to use for an initial learning rate through the overfitting detector, by setting hyperparameters `od_type='Iter', od_wait = 40`.  And then we used that number to then cut our learning rate in half and double the number of iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Catboost parameter docs](https://catboost.ai/docs/concepts/python-reference_parameters-list.html)\n",
    "\n",
    "[Catboost Description and Hyperparameters](https://towardsdatascience.com/https-medium-com-talperetz24-mastering-the-new-generation-of-gradient-boosting-db04062a7ea2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Catboost Tutorial](https://colab.research.google.com/github/catboost/tutorials/blob/master/python_tutorial.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
