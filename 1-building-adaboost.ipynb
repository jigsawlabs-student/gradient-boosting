{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last lesson, we saw the main components of adaboost.  We saw that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We make predictions through a set of classifiers taking a weighted vote for each observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $H(x) = sign\\bigg(\\alpha_1 h_1(x) +\\alpha_2 h_2(x) +\\alpha_3 h_3(x) \\bigg) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. We train each classifier by weighing observations that were previously misclassified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we saw that these two features interact, as \n",
    "\n",
    "1. The value $\\alpha$ for a classifier is determined by a weighted accuracy score, and \n",
    "2. The weight of each observation is partially determined by the value of $\\alpha$, with even more weight assigned to observations misclassified by generally accurate estimators (those with a large $\\alpha$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll build out an adaboost classifier from start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X = pd.DataFrame(cancer['data'], columns = cancer['feature_names'])\n",
    "\n",
    "bool_y = pd.Series(cancer['target'] == 0).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now let's convert the y data to -1 for a negative observation, and + 1 for a positive observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1, -1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1, -1,  1,  1])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y = np.where(bool_y == 0, -1, 1)\n",
    "y[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38           122.8     1001.0          0.11840   \n",
       "1        20.57         17.77           132.9     1326.0          0.08474   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33            184.6   \n",
       "1                 0.05667  ...         24.99          23.41            158.8   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beginning our Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is that we take a weighted sum of the classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $H(x) = sign\\bigg(\\alpha_1 h_1(x) +\\alpha_2 h_2(x) +\\alpha_3 h_3(x) \\bigg) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can train a set of classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtcs = [DecisionTreeClassifier(random_state = i, max_depth = 1, max_features = .1).fit(X_train, y_train) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.07912087912087917, 0.08131868131868136, 0.10989010989010994]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = [1 - dtc.score(X_train, y_train) for dtc in dtcs]\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def alpha(error_t):\n",
    "    return .5*np.log((1 - error_t)/error_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2271759907330135, 1.2122817599402658, 1.0459320308391964]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = [alpha(error) for error in errors]\n",
    "alphas[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we won't go too far into the formula for calculating alpha.  But the main component to see is that the smaller our error is, the larger alpha becomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\alpha_t = \\frac{1}{2}\\ln \\frac{1 - \\epsilon_t}{\\epsilon_t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll add in weighing the observations in the next section.  But for now, with our three models trained and our alphas calculated for each one, we can perform our weighted prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $H(x) = sign\\bigg(\\alpha_1 h_1(x) +\\alpha_2 h_2(x) +\\alpha_3 h_3(x) \\bigg) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dtcs, alphas, X):\n",
    "    preds = np.vstack([alpha*dtc.predict(X) for dtc, alpha in zip(dtcs, alphas)])\n",
    "    cum_preds = preds.sum(axis = 0)\n",
    "    return np.where(cum_preds > 0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,\n",
       "        1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1, -1,  1,  1,\n",
       "       -1, -1,  1, -1,  1, -1, -1, -1,  1,  1,  1, -1,  1, -1,  1,  1, -1,\n",
       "       -1,  1,  1,  1, -1,  1,  1,  1, -1,  1, -1, -1, -1, -1,  1,  1, -1,\n",
       "        1,  1, -1,  1, -1,  1,  1,  1,  1,  1,  1,  1, -1,  1, -1, -1,  1,\n",
       "        1, -1, -1,  1,  1, -1,  1,  1, -1,  1,  1,  1,  1, -1,  1,  1,  1,\n",
       "        1, -1,  1,  1, -1,  1, -1, -1,  1,  1,  1, -1])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = predict(dtcs, alphas, X_test)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighing Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in the last section, we coded our weighted sum of three different estimators.  But we did not train each estimator according to the adaboost procedure.  Remember, with adaboost we train each estimator successively, weighing the samples samples more if they were previously misclassified.  Let's begin to train our classifiers with assigning weights to our observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first classifier, we'll assign the same weight to each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0021978, 0.0021978, 0.0021978, 0.0021978])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "weight_value = 1/y_train.shape[0]\n",
    "\n",
    "w_t = np.full(y_train.shape[0], weight_value)\n",
    "w_t[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign an initial weight of $w_1 = \\frac{1}{n}$, so that every weight is the sample and the sum of the weights add up to one.  Then, we assign weights to each sample as we train our classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth = 2, random_state = 1).fit(X_train, y_train, sample_weight = w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we make predictions, and find the error for our classifier, but we weigh the error by the sample weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = dtc.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046153846153846156"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_hat != y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00010143702451394758"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_incorrect = (y_hat != y_train).astype('int')\n",
    "(w_t*correct_incorrect).sum()/y_hat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(y_hat, y_actual, w_t):\n",
    "    correct_incorrect = (y_hat != y_train).astype('int')\n",
    "    return (w_t*correct_incorrect).sum()/y_hat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00010143702451394758"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_t1 = error(y_hat, y_train, w_t)\n",
    "error_t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And remember, from the error, we can calculate alpha.  With the lower the error, the higher the value of alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.59798547900444"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha(error_t1)\n",
    "alpha(error_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding our New Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've completed a cycle of training and then finding the according alpha value for our decision tree classifier.  But we still haven't covered the component of how to update our weights.\n",
    "\n",
    "Remember that we want to assign a higher weight to those that were classified incorrectly, and a lower weight to those that were classified correctly.\n",
    "\n",
    "This is the formula we'll use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w_t = w_{t - 1}*e^{-\\alpha*y_i*(h_{t-1})} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break this formula down.  For now, let's remove the $\\alpha$ term, so that we have:\n",
    "\n",
    "$w_t = w_{t - 1}*e^{-y_i*h(x)_{t-1}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the $y*h(x)_t-1$ is actually an indicator function.  \n",
    "> * When we incorrectly classify an observation it equals $y*h(x)_{t-1} = -1*1 = -1$ or $1*-1 = -1$, and\n",
    "> * When it correctly classifies an observation, it returns 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So then when we previously correctly classified an observation we weight it by $w_{t-1}*e^{-1}$ and when we incorrectly classify an observation we weight it by $w_{t-1}*e^{1}$. \n",
    "\n",
    "Finally, in the final version we add in the $\\alpha$ term $w_t = w_{t - 1}*e^{-\\alpha*y_i*(h_{t-1})} $.  We can think of this as accentuating our weighting effect based on the size of the $\\alpha$ term, the importance of the classifier.\n",
    "\n",
    "So correctly classified observations by a more accurate classifier are decreased in weight further, and those incorrectly classified are reduced in weight even more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs +</th>\n",
       "      <th>obs -</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model +</th>\n",
       "      <td>w --</td>\n",
       "      <td>w ++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model -</th>\n",
       "      <td>w -</td>\n",
       "      <td>w +</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        obs +  obs -\n",
       "model +  w --  w ++ \n",
       "model -   w -    w +"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'obs +': ['w --', 'w -'],\n",
    "              'obs -': ['w ++ ', 'w +']}, \n",
    "             index = ['model +', 'model -'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = w*np.exp(-alpha*y_train*y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to ensure our weights add up to one, we simply divide by each weight by the sum of the total. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = w/w.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Many Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's loop through this procedure multiple times and see how we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ws = []\n",
    "alphas = []\n",
    "y_hats = []\n",
    "errors = []\n",
    "dtcs = []\n",
    "w = np.ones(y_train.shape[0])/y_train.shape[0]\n",
    "\n",
    "for i in range(30):\n",
    "    dtc = DecisionTreeClassifier(max_depth = 2).fit(X_train, y_train,\n",
    "                                                    sample_weight = w)\n",
    "    y_hat = dtc.predict(X_train)\n",
    "    error_t = w[y_hat != y_train].sum()/y_train.shape[0]\n",
    "    alpha = .5*np.log((1 - error_t)/error_t)\n",
    "    w = w*np.exp(-alpha*y_train*y_hat)\n",
    "    w = w/w.sum()\n",
    "    ws.append(w)\n",
    "    alphas.append(alpha)\n",
    "    y_hats.append(y_hat)\n",
    "    errors.append(error_t)\n",
    "    dtcs.append(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_arr = np.array(alphas)\n",
    "tree_preds = np.array(y_hats) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 455)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00010143702451394758, 1.6422224503675357e-06, 1.6439245142949285e-05]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dtrs, alphas, X):\n",
    "    preds = np.vstack([alpha*dtr.predict(X) for dtr, alpha in zip(dtrs, alphas)])\n",
    "    cum_preds = preds.sum(axis = 0)\n",
    "    return np.where(cum_preds > 0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predict(dtcs, alphas, X_test)\n",
    "predictions[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9912280701754386"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9761904761904762)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_test, predictions), recall_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9512195121951219, 0.9285714285714286)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(min_samples_leaf = 7, max_features = 'log2', \n",
    "                             random_state = 1, n_estimators = 20).fit(X_train, y_train)\n",
    "rfc_predictions = rfc.predict(X_test)\n",
    "\n",
    "precision_score(y_test, rfc_predictions), recall_score(y_test, rfc_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in the above that we were quite successful in our adaboost procedure.  The main new component that we learned was how to update our weights.\n",
    "\n",
    "$w_t = w_{t - 1}*e^{-\\alpha*y_i*(h_{t-1})} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that we do this by using $y_i*h_{t-1}$, to toggle our update between:\n",
    "\n",
    "* $e^{\\alpha}$ when an observation is **incorrectly** classified, and \n",
    "* $\\frac{1}{e^\\alpha}$ when a weight is **correctly** classified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this leads each successive classifier to provide more weight to observations that were previously classified incorrectly, and especially by influential classifiers.\n",
    "\n",
    "After going through one cycle, we then trained thirty successive decision trees to train a model that outperformed our random forest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
